# Importa bibliotecas para importação de dados e EDA
import pandas as pd
import numpy as np
import json
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns





# Define configurações do pandas
pd.set_option('display.max_columns', None)


# Define caminho
raw_data_path = Path('data/raw')

# Verifica arquivos presentes no diretório
print("Arquivos disponíveis:", list(raw_data_path.iterdir()))


# Cria função que carrega um JSON estruturado em dicionário e converte em df
def carregar_e_processar_json(nome_arquivo):
    caminho = Path('data/raw') / nome_arquivo

    with open(caminho, 'r', encoding='utf-8') as f:
        dados = json.load(f)

    # Se o JSON for um dicionário e o valor da primeira chave for uma lista
    if isinstance(dados, dict):
        primeiro_valor = list(dados.values())[0]
        if isinstance(primeiro_valor, list):
            df = pd.DataFrame(primeiro_valor)
        else:
            df = pd.DataFrame.from_dict(dados, orient='index')
            df.reset_index(inplace=True)
            df.rename(columns={'index': 'id'}, inplace=True)
    elif isinstance(dados, list):
        df = pd.DataFrame(dados)
    else:
        raise ValueError("Formato de JSON não suportado.")

    return df


# Cria um for loop que itera pelos arquivos .json na pasta,
# carrega cada um como df, normaliza a estrutura, atribui um nome 
# e armazena no dicionário 'dataframes'

dataframes = {}

for arquivo in raw_data_path.glob('*.json'):
    nome_base = arquivo.stem  # ex: 'vagas'
    nome_variavel = f'df_{nome_base}'  # ex: 'df_vagas'
    df = carregar_e_processar_json(arquivo.name)
    dataframes[nome_variavel] = df

# Transforma os itens do dicionário em variáveis
globals().update(dataframes)

# Exibe os nomes das variáveis criadas e o tamanho de cada df
for nome, df in dataframes.items():
    print(f'{nome}: {df.shape}')


# Cria funções por df para planificar as bases
def planificar_vagas(df):
    df = df.join(pd.json_normalize(df['informacoes_basicas']))
    df = df.join(pd.json_normalize(df['perfil_vaga']))
    df = df.join(pd.json_normalize(df['beneficios']))
    return df.drop(columns=['informacoes_basicas', 'perfil_vaga', 'beneficios'])

def planificar_prospects(df):
    df = df.explode('prospects', ignore_index=True)
    df = pd.concat([df.drop(columns=['prospects']), pd.json_normalize(df['prospects'])], axis=1)
    return df

def planificar_applicants(df):
    for coluna in ['infos_basicas', 'informacoes_pessoais', 'informacoes_profissionais', 'formacao_e_idiomas']:
        df_norm = pd.json_normalize(df[coluna])
        df_norm.columns = [f"{coluna}_{subcol}" for subcol in df_norm.columns]
        df = df.join(df_norm)
        df.drop(columns=[coluna], inplace=True)
    return df

# Aplica as funções e cria novas variáveis
df_vagas_exp = planificar_vagas(df_vagas)
df_prospects_exp = planificar_prospects(df_prospects)
df_applicants_exp = planificar_applicants(df_applicants)


# Verifica primeiras linhas de vagas
df_vagas_exp.head(2)


# Verifica primeiras linhas de prospects
df_prospects_exp.head(2)


# Verifica primeiras linhas de applicants
df_applicants_exp.head(2)





# Corrige nomes de colunas com erros
df_vagas_exp.rename(columns={
    'data_requicisao': 'data_requisicao',
    'nivel profissional': 'nivel_profissional',
    'id': 'id_vaga'
}, inplace=True)

# Cria cópia de df vagas
df_vagas_tratado = df_vagas_exp.copy()

# Corrige tipos de dados

# Datas
df_vagas_tratado['data_requisicao'] = pd.to_datetime(df_vagas_tratado['data_requisicao'], errors='coerce',dayfirst=True)
df_vagas_tratado['limite_esperado_para_contratacao'] = pd.to_datetime(df_vagas_tratado['limite_esperado_para_contratacao'], errors='coerce',dayfirst=True)
df_vagas_tratado['data_inicial'] = pd.to_datetime(df_vagas_tratado['data_inicial'], errors='coerce',dayfirst=True)
df_vagas_tratado['data_final'] = pd.to_datetime(df_vagas_tratado['data_final'], errors='coerce',dayfirst=True)

# Numéricas
df_vagas_tratado['id_vaga'] = pd.to_numeric(df_vagas_tratado['id_vaga'], errors='coerce')
df_vagas_tratado['local_trabalho'] = pd.to_numeric(df_vagas_tratado['local_trabalho'], errors='coerce')

# Mantém telefone como string
df_vagas_tratado['telefone'] = df_vagas_tratado['telefone'].astype(str)

# Converte colunas binárias mapeando em 0 e 1
df_vagas_tratado['vaga_sap'] = df_vagas_tratado['vaga_sap'].map({'Sim': 1, 'Não': 0})
df_vagas_tratado['vaga_especifica_para_pcd'] = df_vagas_tratado['vaga_especifica_para_pcd'].map({'Sim': 1, 'Não': 0})
df_vagas_tratado['viagens_requeridas'] = df_vagas_tratado['viagens_requeridas'].map({'Sim': 1, 'Não': 0})

#  Categóricas
colunas_categoricas = [
    'titulo_vaga', 'cliente', 'solicitante_cliente', 'empresa_divisao', 'requisitante',
    'analista_responsavel', 'tipo_contratacao', 'prazo_contratacao', 'prioridade_vaga',
    'origem_vaga', 'nome', 'nome_substituto', 'pais', 'estado', 'cidade', 'bairro', 'regiao',
    'horario_trabalho', 'nivel_profissional', 'nivel_academico', 'nivel_ingles',
    'nivel_espanhol', 'outro_idioma', 'areas_atuacao', 'equipamentos_necessarios'
]
df_vagas_tratado[colunas_categoricas] = df_vagas_tratado[colunas_categoricas].astype('category')

# Dropa colunas irrelevantes para classificação e clustering
colunas_vagas_drop = [
    'principais_atividades', 'competencia_tecnicas_e_comportamentais',
    'demais_observacoes', 'habilidades_comportamentais_necessarias', 'valor_venda',
    'valor_compra_1', 'valor_compra_2', 'cliente', 'solicitante_cliente', 'empresa_divisao',
    'requisitante', 'analista_responsavel', 'nome', 'telefone', 'nome_substituto', 'pais'
]
df_vagas_tratado.drop(columns=colunas_vagas_drop, inplace=True)

# Verifica info alterada
df_vagas_tratado.info()


df_vagas_tratado.head()


# Cria cópia de df applicants
df_applicants_tratado = df_applicants_exp.copy()

# Renomeia colunas
df_applicants_tratado.rename(columns={
    'id': 'id_candidato'
}, inplace=True)

# Corrige tipos de dados

# Datas
df_applicants_tratado['infos_basicas_data_criacao'] = pd.to_datetime(df_applicants_tratado['infos_basicas_data_criacao'], errors='coerce', dayfirst=True)
df_applicants_tratado['infos_basicas_data_atualizacao'] = pd.to_datetime(df_applicants_tratado['infos_basicas_data_atualizacao'], errors='coerce', dayfirst=True)
# data_nascimento não vamos tipar, pois será removido

# Numéricos
df_applicants_tratado['id_candidato'] = pd.to_numeric(df_applicants_tratado['id_candidato'], errors='coerce')
df_applicants_tratado['formacao_e_idiomas_ano_conclusao'] = pd.to_numeric(df_applicants_tratado['formacao_e_idiomas_ano_conclusao'], errors='coerce')
df_applicants_tratado['informacoes_profissionais_remuneracao'] = pd.to_numeric(df_applicants_tratado['informacoes_profissionais_remuneracao'], errors='coerce')

# Converte colunas binárias mapeando em 0 e 1
df_applicants_tratado['informacoes_pessoais_pcd'] = df_applicants_tratado['informacoes_pessoais_pcd'].map({'Sim': 1, 'Não': 0})

# Categóricas
colunas_categoricas_applicants = [
    'infos_basicas_objetivo_profissional', 'infos_basicas_local', 'infos_basicas_sabendo_de_nos_por',
    'informacoes_pessoais_sexo', 'informacoes_pessoais_estado_civil',
    'informacoes_profissionais_area_atuacao', 'informacoes_profissionais_nivel_profissional',
    'formacao_e_idiomas_nivel_academico', 'formacao_e_idiomas_nivel_ingles',
    'formacao_e_idiomas_nivel_espanhol', 'formacao_e_idiomas_outro_idioma',
    'formacao_e_idiomas_instituicao_ensino_superior', 'formacao_e_idiomas_cursos', 
    'infos_basicas_codigo_profissional'
]

df_applicants_tratado[colunas_categoricas_applicants] = df_applicants_tratado[colunas_categoricas_applicants].astype('category')

# Dropa colunas irrelevantes para classificação e clustering
colunas_remover_applicants = [
    'cargo_atual', 'cv_pt', 'cv_en',
    'infos_basicas_telefone_recado',
    'informacoes_pessoais_data_aceite', 'informacoes_pessoais_nome', 'informacoes_pessoais_cpf',
    'informacoes_pessoais_fonte_indicacao', 'informacoes_pessoais_email', 'informacoes_pessoais_email_secundario',
    'informacoes_pessoais_data_nascimento', 'informacoes_pessoais_telefone_celular',
    'informacoes_pessoais_telefone_recado', 'informacoes_pessoais_endereco',
    'informacoes_pessoais_skype', 'informacoes_pessoais_url_linkedin', 'informacoes_pessoais_facebook',
    'informacoes_pessoais_download_cv', 'informacoes_profissionais_titulo_profissional',
    'informacoes_profissionais_conhecimentos_tecnicos', 'informacoes_profissionais_certificacoes',
    'informacoes_profissionais_outras_certificacoes', 'informacoes_profissionais_qualificacoes',
    'informacoes_profissionais_experiencias', 'formacao_e_idiomas_outro_curso', 'infos_basicas_telefone',
    'infos_basicas_nome','infos_basicas_inserido_por','infos_basicas_objetivo_profissional'
]

df_applicants_tratado.drop(columns=colunas_remover_applicants, inplace=True)

# Exibe estrutura final
df_applicants_tratado.info()


# Cria cópia de df prospects
df_prospects_tratado = df_prospects_exp.copy()

# Renomeia colunas
df_prospects_tratado.rename(columns={
    'id': 'id_vaga',
    'codigo': 'id_candidato',
    'situacao_candidado': 'situacao_candidato' 
}, inplace=True)

# Corrige tipos de dados

# Inteiro
df_prospects_tratado['id_vaga'] = pd.to_numeric(df_prospects_tratado['id_vaga'], errors='coerce')
df_prospects_tratado['id_candidato'] = pd.to_numeric(df_prospects_tratado['id_candidato'], errors='coerce')

# Datas
df_prospects_tratado['data_candidatura'] = pd.to_datetime(df_prospects_tratado['data_candidatura'], errors='coerce', dayfirst=True)
df_prospects_tratado['ultima_atualizacao'] = pd.to_datetime(df_prospects_tratado['ultima_atualizacao'], errors='coerce', dayfirst=True)

# Categóricas
df_prospects_tratado['modalidade'] = df_prospects_tratado['modalidade'].astype('category')
df_prospects_tratado['situacao_candidato'] = df_prospects_tratado['situacao_candidato'].astype('category')

# Dropa colunas irrelevantes
colunas_remover_prospects = ['titulo', 'nome', 'comentario', 'recrutador']
df_prospects_tratado.drop(columns=colunas_remover_prospects, inplace=True)

# Exibe estrutura final
df_prospects_tratado.info()


# Une as baes num df único
df_merged = (
    df_prospects_tratado
    .merge(df_vagas_tratado.rename(columns={'id': 'id_vaga'}), on='id_vaga', how='left')
    .merge(df_applicants_tratado.rename(columns={'id': 'id_candidato'}), on='id_candidato', how='left')
)

# Cria lista de colunas a remover
colunas_remover_df_merged = [
    'id_vaga',
    'modalidade',
    'id_candidato',
    'limite_esperado_para_contratacao',
    'titulo_vaga',
    'limite_esperado_para_contratacao',
    'objetivo_vaga',
    'origem_vaga',
    'bairro',
    'regiao',
    'viagens_requeridas',
    'equipamentos_necessarios',
    'infos_basicas_data_criacao',
    'infos_basicas_email',
    'infos_basicas_local',
    'infos_basicas_sabendo_de_nos_por',
    'infos_basicas_data_atualizacao',
    'infos_basicas_codigo_profissional',
    'formacao_e_idiomas_instituicao_ensino_superior',
    'superior_imediato',
    'cidade',
    'vaga_especifica_para_pcd',
    'informacoes_profissionais_nivel_profissional',
    'formacao_e_idiomas_cursos',
    'formacao_e_idiomas_instituicao_ensino_superior',
    'formacao_e_idiomas_outro_idioma',
    'informacoes_profissionais_nivel_profissional',
    'ultima_atualizacao',
    'data_inicial',
    'data_final',
    'data_candidatura',
    'data_requisicao',
    'outro_idioma',
    'faixa_etaria',
    'estado',
    'horario_trabalho',
    'informacoes_pessoais_pcd',
    'informacoes_profissionais_area_atuacao',
    'areas_atuacao',
    'local_trabalho',
    'tipo_contratacao',
    'vaga_sap',
    'informacoes_profissionais_remuneracao'
]

# Remove colunas
df_merged = df_merged.drop(colunas_remover_df_merged, axis=1)


# Cria dicionárioa para renomear colunas
dict_renomear_coluna_merged = {
    'nivel_profissional': 'nivel_profissional_vaga',
    'nivel_academico': 'nivel_academico_vaga',
    'nivel_ingles': 'nivel_ingles_vaga',
    'nivel_espanhol': 'nivel_espanhol_vaga',
    'areas_atuacao': 'areas_atuacao_vaga',
    'informacoes_pessoais_sexo': 'genero_candidato',
    'informacoes_pessoais_estado_civil': 'estado_civil_candidato',
    'informacoes_profissionais_area_atuacao': 'area_atuacao_candidato',
    'informacoes_profissionais_remuneracao': 'remuneracao_candidato',
    'formacao_e_idiomas_nivel_academico': 'nivel_academico_candidato',
    'formacao_e_idiomas_nivel_ingles': 'nivel_ingles_candidato',
    'formacao_e_idiomas_nivel_espanhol': 'nivel_espanhol_candidato',
    'formacao_e_idiomas_ano_conclusao': 'ano_conclusao_candidato'
}

# Renomeia coluas
df_merged = df_merged.rename(columns=dict_renomear_coluna_merged)

# Exibe primeiras linhas do df
df_merged.head(2)


# Verifica informações sobre df
df_merged.info()





# Análise da variável target
df_merged['situacao_candidato'].value_counts(normalize=True).round(2)


# Definição de novo df com remoção das etapas prospet e encaminhado ao requisitante,
# considerá-las como 0 poderia introduzir viés ao modelo de participantes que ainda
# estão em processo não finalizado. Também são removidos valores NaN.

df_model = df_merged[
    (~df_merged['situacao_candidato'].isin(['Prospect', 'Encaminhado ao Requisitante'])) &
    (df_merged['situacao_candidato'].notna())
].copy()

# Define lista de situações que representam contratação
situacoes_contratado = [
    'Contratado pela Decision',
    'Contratado como Hunting',
    'Aprovado',
    'Proposta Aceita'
]

# Aplica binarização da variável target
df_model['target_contratado'] = df_model['situacao_candidato'].apply(
    lambda x: 1 if x in situacoes_contratado else 0
)

# Dropa coluna de situacao candidato
df_model.drop(columns='situacao_candidato', inplace=True)

# Exibe distribuição
df_model['target_contratado'].value_counts(normalize=True)


# Cria lista de colunas para tratar com valores ausentes
colunas_para_tratar = [
    'prioridade_vaga',
    'nivel_profissional_vaga',
    'prazo_contratacao',
    'nivel_academico_vaga',
    'nivel_ingles_vaga',
    'nivel_espanhol_vaga',
    'genero_candidato',
    'estado_civil_candidato',
    'nivel_academico_candidato',
    'nivel_ingles_candidato',
    'nivel_espanhol_candidato',
]

# Cria função para preencher valores em colunas com brancos e nulos
def preencher_com_nao_informado(df, colunas):
    for col in colunas:
        # Substitui strings vazias e espaços por NaN
        df[col] = df[col].replace(r'^\s*$', np.nan, regex=True)

        # Se a coluna for do tipo category, adiciona a nova categoria explicitamente
        if pd.api.types.is_categorical_dtype(df[col]):
            if 'Não informado' not in df[col].cat.categories:
                df[col] = df[col].cat.add_categories('Não informado')

        # Preenche valores ausentes
        df[col] = df[col].fillna('Não informado')

        # Se não for category ainda, converte agora
        if not pd.api.types.is_categorical_dtype(df[col]):
            df[col] = df[col].astype('category')

    return df

# Aplica função
df_model = preencher_com_nao_informado(df_model, colunas_para_tratar)


# Converte para string temporariamente
df_model['prioridade_vaga'] = df_model['prioridade_vaga'].astype(str)

# Aplica substituições
df_model['prioridade_vaga'] = df_model['prioridade_vaga'].replace({
    'Alta: Alta complexidade 3 a 5 dias': 'Alta',
    'Média: Média complexidade 6 a 10 dias': 'Média',
    'Baixa: Baixa complexidade 11 a 30 dias': 'Baixa',
    '': 'Não informado',
    'nan': 'Não informado'
})

# Reconverte para category
df_model['prioridade_vaga'] = df_model['prioridade_vaga'].astype('category')


from datetime import datetime

# Define o ano atual
ano_atual = datetime.now().year

# Trata valores inválidos
df_model['ano_conclusao_candidato'] = df_model['ano_conclusao_candidato'].apply(
    lambda x: np.nan if pd.isna(x) or x < 1950 or x > ano_atual else x
)

# Cria nova coluna de anos desde a formação
df_model['anos_desde_formacao'] = df_model['ano_conclusao_candidato'].apply(
    lambda x: ano_atual - x if not pd.isna(x) else np.nan
)

# Cria faixas de tempo desde a formação
bins = [0, 2, 5, 10, 20, np.inf]
labels = ['Recente (0-2 anos)', 'Novo (3-5)', 'Experiente (6-10)', 'Sênior (11-20)', 'Veterano (20+)']

df_model['faixa_experiencia_formacao'] = pd.cut(df_model['anos_desde_formacao'], bins=bins, labels=labels)

# Preenche nulos
df_model['faixa_experiencia_formacao'] = df_model['faixa_experiencia_formacao'].cat.add_categories('Não informado')
df_model['faixa_experiencia_formacao'] = df_model['faixa_experiencia_formacao'].fillna('Não informado')

# Dropa coluna original
df_model.drop(columns=['ano_conclusao_candidato', 'anos_desde_formacao'], inplace=True)


# Exibe vesão final do df para EDA
df_model.head(2)





# Informações do df
df_model.info()


# Plota distribuição do target
sns.countplot(x='target_contratado', data=df_model)
plt.title('Distribuição do target')





# Exibe percentual da distribuição do target
df_model['target_contratado'].value_counts(normalize=True).round(3) * 100





# Cria função para análise de coluna categórica com taxa de contratação
def analisar_todas_categoricas(df, target_col='target_contratado'):
    """
    Para cada coluna categórica (exceto o target), exibe:
    - Tabela com Total, Contratados e Taxa de Contratação
    - Gráfico de barras da taxa por categoria
    """
    colunas = df.select_dtypes(include='category').columns
    colunas = [col for col in colunas if col != target_col]

    for col in colunas:
        print(f"\n\nAnálise da variável: {col}\n")

        resumo = (
            df.groupby(col, observed=True)[target_col]  # elimina FutureWarning
            .agg(Total='count', Contratado='sum', Taxa_contratacao='mean')
            .sort_values('Total', ascending=False)
        )

        display(resumo)

        plt.figure(figsize=(8, 4))
        sns.barplot(
            x=resumo.index,
            y=resumo['Taxa_contratacao'],
            hue=resumo.index,         # elimina warning do palette
            palette='viridis',
            legend=False
        )
        plt.title(f'Taxa de Contratação por {col}')
        plt.ylabel('Taxa de Contratação')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

# Executa a análise
analisar_todas_categoricas(df_model)
